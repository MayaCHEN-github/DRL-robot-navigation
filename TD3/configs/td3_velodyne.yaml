algorithm: TD3
env: VelodyneEnv
n_timesteps: 250000
policy: MlpPolicy
seed: 0

policy_kwargs:
  net_arch: [256, 256]

learning_rate: 1e-4
buffer_size: 1000000
batch_size: 40
tau: 0.005
gamma: 0.99999
policy_delay: 2
target_policy_noise: 0.2
target_noise_clip: 0.5
exploration_noise: 1.0
exploration_noise_decay: 0.999
exploration_noise_min: 0.1

# 训练配置
eval_freq: 5000
n_eval_episodes: 5
log_freq: 100

gym_wrapper: true
wrapper_kwargs:
  launchfile: multi_robot_scenario.launch
  environment_dim: 20
  action_type: continuous
  device: auto